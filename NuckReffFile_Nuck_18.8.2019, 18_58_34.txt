0$$$Holzinger, A., Biemann, C., Pattichis, C. S., & Kell, D. B. (2017). What do we need to build explainable AI systems for the medical domain?. arXiv preprint arXiv:1712.09923.$$$@article{holzinger2017we,   title={What do we need to build explainable AI systems for the medical domain?},   author={Holzinger, Andreas and Biemann, Chris and Pattichis, Constantinos S and Kell, Douglas B},   journal={arXiv preprint arXiv:1712.09923},   year={2017} }$$$What do we need to build explainable AI systems for the medical domain?$$$2017$$$Holzinger$$$5$$$rainyDay$$$unprinted$$$https://arxiv.org/pdf/1712.09923$$$IUI$$$$$$$$$$$$$$$$$$$$$$$$$$$AI;Explanation;Medicine;$$$0
1$$$Biran, O., & Cotton, C. (2017, August). Explanation and justification in machine learning: A survey. In IJCAI-17 workshop on explainable AI (XAI) (Vol. 8, p. 1).$$$@inproceedings{biran2017explanation,   title={Explanation and justification in machine learning: A survey},   author={Biran, Or and Cotton, Courtenay},   booktitle={IJCAI-17 workshop on explainable AI (XAI)},   volume={8},   pages={1},   year={2017} }$$$Explanation and Justification in Machine Learning: A Survey$$$2017$$$Biran$$$6$$$read$$$unprinted$$$http://www.cs.columbia.edu/~orb/papers/xai_survey_paper_2017.pdf$$$XAI@IJCAI$$$Survey of the research concerning explanation and justification in the Machine Learning$$$$$$$$$$$$$$$$$$$$$Explanations = increased ability to predict system's behaviour and increased trust; types of ML systems = inherently interpretable and opaque systems$$$Theory;Explanability;Trust;$$$0
